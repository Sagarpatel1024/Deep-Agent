{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa889d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "import uuid, base64\n",
    "\n",
    "import httpx\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.messages import HumanMessage, ToolMessage\n",
    "from langchain_core.tools import InjectedToolArg, InjectedToolCallId, tool\n",
    "from langgraph.prebuilt import InjectedState\n",
    "from langgraph.types import Command\n",
    "from markdownify import markdownify\n",
    "from pydantic import BaseModel, Field\n",
    "from tavily import TavilyClient\n",
    "from typing_extensions import Annotated, Literal\n",
    "\n",
    "from deep_agents_from_scratch.prompts import SUMMARIZE_WEB_SEARCH\n",
    "from deep_agents_from_scratch.state import DeepAgentState\n",
    "\n",
    "# Summarization model \n",
    "summarization_model = init_chat_model(model=\"openai:gpt-4o-mini\")\n",
    "tavily_client = TavilyClient()\n",
    "\n",
    "class Summary(BaseModel):\n",
    "    \"\"\"Schema for webpage content summarization.\"\"\"\n",
    "    filename: str = Field(description=\"Name of the file to store.\")\n",
    "    summary: str = Field(description=\"Key learnings from the webpage.\")\n",
    "\n",
    "def get_today_str() -> str:\n",
    "    \"\"\"Get current date in a human-readable format.\"\"\"\n",
    "    return datetime.now().strftime(\"%a %b %-d, %Y\")\n",
    "\n",
    "def run_tavily_search(\n",
    "    search_query: str, \n",
    "    max_results: int = 1, \n",
    "    topic: Literal[\"general\", \"news\", \"finance\"] = \"general\", \n",
    "    include_raw_content: bool = True, \n",
    ") -> dict:\n",
    "    \"\"\"Perform search using Tavily API for a single query.\n",
    "\n",
    "    Args:\n",
    "        search_query: Search query to execute\n",
    "        max_results: Maximum number of results per query\n",
    "        topic: Topic filter for search results\n",
    "        include_raw_content: Whether to include raw webpage content\n",
    "\n",
    "    Returns:\n",
    "        Search results dictionary\n",
    "    \"\"\"\n",
    "    result = tavily_client.search(\n",
    "        search_query,\n",
    "        max_results=max_results,\n",
    "        include_raw_content=include_raw_content,\n",
    "        topic=topic\n",
    "    )\n",
    "\n",
    "    return result\n",
    "\n",
    "def summarize_webpage_content(webpage_content: str) -> Summary:\n",
    "    \"\"\"Summarize webpage content using the configured summarization model.\n",
    "    \n",
    "    Args:\n",
    "        webpage_content: Raw webpage content to summarize\n",
    "        \n",
    "    Returns:\n",
    "        Summary object with filename and summary\n",
    "    \"\"\"\n",
    "    try:\n",
    "        structured_model = summarization_model.with_structured_output(Summary)\n",
    "        \n",
    "        summary_and_filename = structured_model.invoke([\n",
    "            HumanMessage(content=SUMMARIZE_WEB_SEARCH.format(\n",
    "                webpage_content=webpage_content, \n",
    "                date=get_today_str()\n",
    "            ))\n",
    "        ])\n",
    "        \n",
    "        return summary_and_filename\n",
    "        \n",
    "    except Exception:\n",
    "        return Summary(\n",
    "            filename=\"search_result.md\",\n",
    "            summary=webpage_content[:1000] + \"...\" if len(webpage_content) > 1000 else webpage_content\n",
    "        )\n",
    "\n",
    "\n",
    "def process_search_results(results: dict) -> list[dict]:\n",
    "    \"\"\"Process search results by summarizing content where available.\n",
    "\n",
    "    Args:\n",
    "        results: Tavily search results dictionary\n",
    "\n",
    "    Returns:\n",
    "        List of processed results with summaries\n",
    "    \"\"\"\n",
    "    processed_results = []\n",
    "\n",
    "    HTTPX_CLIENT = httpx.Client(timeout=30.0)  \n",
    "\n",
    "    for result in results.get('results', []):\n",
    " \n",
    "        url = result['url']\n",
    "\n",
    "        try:\n",
    "            response = HTTPX_CLIENT.get(url)\n",
    "        \n",
    "            if response.status_code == 200:\n",
    "\n",
    "                raw_content = markdownify(response.text)\n",
    "                summary_obj = summarize_webpage_content(raw_content)\n",
    "            else:\n",
    "                raw_content = result.get('raw_content', '')\n",
    "                summary_obj = Summary(\n",
    "                    filename=\"URL_error.md\",\n",
    "                    summary=result.get('content', 'Error reading URL; try another search.')\n",
    "                )\n",
    "        except (httpx.TimeoutException, httpx.RequestError) as e:\n",
    "            raw_content = result.get('raw_content', '')\n",
    "            summary_obj = Summary(\n",
    "                filename=\"connection_error.md\",\n",
    "                summary=result.get('content', f'Could not fetch URL (timeout/connection error). Try another search.')\n",
    "            )\n",
    "\n",
    "\n",
    "        uid = base64.urlsafe_b64encode(uuid.uuid4().bytes).rstrip(b\"=\").decode(\"ascii\")[:8]\n",
    "        name, ext = os.path.splitext(summary_obj.filename)\n",
    "        summary_obj.filename = f\"{name}_{uid}{ext}\"\n",
    "\n",
    "        processed_results.append({\n",
    "            'url': result['url'],\n",
    "            'title': result['title'],\n",
    "            'summary': summary_obj.summary,\n",
    "            'filename': summary_obj.filename,\n",
    "            'raw_content': raw_content,\n",
    "        })\n",
    "\n",
    "    return processed_results\n",
    "\n",
    "\n",
    "@tool(parse_docstring=True)\n",
    "def tavily_search(\n",
    "    query: str,\n",
    "    state: Annotated[DeepAgentState, InjectedState],\n",
    "    tool_call_id: Annotated[str, InjectedToolCallId],\n",
    "    max_results: Annotated[int, InjectedToolArg] = 1,\n",
    "    topic: Annotated[Literal[\"general\", \"news\", \"finance\"], InjectedToolArg] = \"general\",\n",
    ") -> Command:\n",
    "    \"\"\"Search web and save detailed results to files while returning minimal context.\n",
    "\n",
    "    Performs web search and saves full content to files for context offloading.\n",
    "    Returns only essential information to help the agent decide on next steps.\n",
    "\n",
    "    Args:\n",
    "        query: Search query to execute\n",
    "        state: Injected agent state for file storage\n",
    "        tool_call_id: Injected tool call identifier\n",
    "        max_results: Maximum number of results to return (default: 1)\n",
    "        topic: Topic filter - 'general', 'news', or 'finance' (default: 'general')\n",
    "\n",
    "    Returns:\n",
    "        Command that saves full results to files and provides minimal summary\n",
    "    \"\"\"\n",
    "\n",
    "    search_results = run_tavily_search(\n",
    "        query,\n",
    "        max_results=max_results,\n",
    "        topic=topic,\n",
    "        include_raw_content=True,\n",
    "    ) \n",
    "\n",
    "\n",
    "    processed_results = process_search_results(search_results)\n",
    "    \n",
    "\n",
    "    files = state.get(\"files\", {})\n",
    "    saved_files = []\n",
    "    summaries = []\n",
    "    \n",
    "    for i, result in enumerate(processed_results):\n",
    "\n",
    "        filename = new_func(result)\n",
    "        \n",
    "        file_content = f\"\"\"# Search Result: {result['title']}\n",
    "\n",
    "**URL:** {result['url']}\n",
    "**Query:** {query}\n",
    "**Date:** {get_today_str()}\n",
    "\n",
    "## Summary\n",
    "{result['summary']}\n",
    "\n",
    "## Raw Content\n",
    "{result['raw_content'] if result['raw_content'] else 'No raw content available'}\n",
    "\"\"\"\n",
    "        \n",
    "        files[filename] = file_content\n",
    "        saved_files.append(filename)\n",
    "        summaries.append(f\"- {filename}: {result['summary']}...\")\n",
    "    \n",
    "    summary_text = f\"\"\"üîç Found {len(processed_results)} result(s) for '{query}':\n",
    "\n",
    "{chr(10).join(summaries)}\n",
    "\n",
    "Files: {', '.join(saved_files)}\n",
    "üí° Use read_file() to access full details when needed.\"\"\"\n",
    "\n",
    "    return Command(\n",
    "        update={\n",
    "            \"files\": files,\n",
    "            \"messages\": [\n",
    "                ToolMessage(summary_text, tool_call_id=tool_call_id)\n",
    "            ],\n",
    "        }\n",
    "    )\n",
    "\n",
    "def new_func(result):\n",
    "    filename = result['filename']\n",
    "    return filename\n",
    "\n",
    "@tool(parse_docstring=True)\n",
    "def think_tool(reflection: str) -> str:\n",
    "    \"\"\"Tool for strategic reflection on research progress and decision-making.\n",
    "\n",
    "    Use this tool after each search to analyze results and plan next steps systematically.\n",
    "    This creates a deliberate pause in the research workflow for quality decision-making.\n",
    "\n",
    "    When to use:\n",
    "    - After receiving search results: What key information did I find?\n",
    "    - Before deciding next steps: Do I have enough to answer comprehensively?\n",
    "    - When assessing research gaps: What specific information am I still missing?\n",
    "    - Before concluding research: Can I provide a complete answer now?\n",
    "    - How complex is the question: Have I reached the number of search limits?\n",
    "\n",
    "    Reflection should address:\n",
    "    1. Analysis of current findings - What concrete information have I gathered?\n",
    "    2. Gap assessment - What crucial information is still missing?\n",
    "    3. Quality evaluation - Do I have sufficient evidence/examples for a good answer?\n",
    "    4. Strategic decision - Should I continue searching or provide my answer?\n",
    "\n",
    "    Args:\n",
    "        reflection: Your detailed reflection on research progress, findings, gaps, and next steps\n",
    "\n",
    "    Returns:\n",
    "        Confirmation that reflection was recorded for decision-making\n",
    "    \"\"\"\n",
    "    return f\"Reflection recorded: {reflection}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afe01ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "from IPython.display import Image, display\n",
    "from langchain_openai import ChatOpenAI\n",
    "#from langgraph.prebuilt import create_react_agent\n",
    "from langchain.agents import create_agent\n",
    "\n",
    "from deep_agents_from_scratch.file_tools import ls, read_file, write_file\n",
    "from deep_agents_from_scratch.prompts import (\n",
    "    FILE_USAGE_INSTRUCTIONS,\n",
    "    RESEARCHER_INSTRUCTIONS,\n",
    "    SUBAGENT_USAGE_INSTRUCTIONS,\n",
    "    TODO_USAGE_INSTRUCTIONS,\n",
    ")\n",
    "from deep_agents_from_scratch.research_tools import tavily_search, think_tool, get_today_str\n",
    "from deep_agents_from_scratch.state import DeepAgentState\n",
    "from deep_agents_from_scratch.task_tool import _create_task_tool\n",
    "from deep_agents_from_scratch.todo_tools import write_todos, read_todos\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "\n",
    "max_concurrent_research_units = 3\n",
    "max_researcher_iterations = 3\n",
    "\n",
    "sub_agent_tools = [tavily_search, think_tool]\n",
    "built_in_tools = [ls, read_file, write_file, write_todos, read_todos, think_tool]\n",
    "\n",
    "research_sub_agent = {\n",
    "    \"name\": \"research-agent\",\n",
    "    \"description\": \"Delegate research to the sub-agent researcher. Only give this researcher one topic at a time.\",\n",
    "    \"prompt\": RESEARCHER_INSTRUCTIONS.format(date=get_today_str()),\n",
    "    \"tools\": [\"tavily_search\", \"think_tool\"],\n",
    "}\n",
    "\n",
    "\n",
    "task_tool = _create_task_tool(\n",
    "    sub_agent_tools, [research_sub_agent], model, DeepAgentState\n",
    ")\n",
    "\n",
    "delegation_tools = [task_tool]\n",
    "all_tools = sub_agent_tools + built_in_tools + delegation_tools \n",
    "\n",
    "\n",
    "SUBAGENT_INSTRUCTIONS = SUBAGENT_USAGE_INSTRUCTIONS.format(\n",
    "    max_concurrent_research_units=max_concurrent_research_units,\n",
    "    max_researcher_iterations=max_researcher_iterations,\n",
    "    date=datetime.now().strftime(\"%a %b %d, %Y\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0ef9c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "INSTRUCTIONS = (\n",
    "    \"# TODO MANAGEMENT\\n\"\n",
    "    + TODO_USAGE_INSTRUCTIONS\n",
    "    + \"\\n\\n\"\n",
    "    + \"=\" * 80\n",
    "    + \"\\n\\n\"\n",
    "    + \"# FILE SYSTEM USAGE\\n\"\n",
    "    + FILE_USAGE_INSTRUCTIONS\n",
    "    + \"\\n\\n\"\n",
    "    + \"=\" * 80\n",
    "    + \"\\n\\n\"\n",
    "    + \"# SUB-AGENT DELEGATION\\n\"\n",
    "    + SUBAGENT_INSTRUCTIONS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d24f2f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "agent = create_agent( \n",
    "    model, all_tools, system_prompt=INSTRUCTIONS, state_schema=DeepAgentState\n",
    ")\n",
    "\n",
    "\n",
    "display(Image(agent.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99c7383f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "result = agent.invoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"Give me an overview of Model Context Protocol (MCP).\",\n",
    "            }\n",
    "        ],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c8dac18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Give me an overview of Model Context Protocol (MCP).', additional_kwargs={}, response_metadata={}, id='01188e34-d6ad-4090-86fe-b8d5a73c02c8'),\n",
       "  AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 35, 'prompt_tokens': 1880, 'total_tokens': 1915, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_3683ee3deb', 'id': 'chatcmpl-CsWKGwz9ZK8sYnD4UnwgpbZxZh2Ws', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--019b6ff6-d975-7111-9d2d-b5a625e30198-0', tool_calls=[{'name': 'write_todos', 'args': {'todos': [{'content': 'Research the Model Context Protocol (MCP) and provide an overview.', 'status': 'pending'}]}, 'id': 'call_K5ZNNO0Y7TZrRurXpUUcbnQx', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1880, 'output_tokens': 35, 'total_tokens': 1915, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  ToolMessage(content=\"Updated todo list to [{'content': 'Research the Model Context Protocol (MCP) and provide an overview.', 'status': 'pending'}]\", name='write_todos', id='a93fc06f-9794-4989-b0c6-704b5ddea620', tool_call_id='call_K5ZNNO0Y7TZrRurXpUUcbnQx'),\n",
       "  AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 1953, 'total_tokens': 1964, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_c4585b5b9c', 'id': 'chatcmpl-CsWKJJyKSbnQ8Hf6XAzqybjyANmcg', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--019b6ff6-e6ef-73a2-bff5-af3d0996ba0c-0', tool_calls=[{'name': 'read_todos', 'args': {}, 'id': 'call_2YEjZ1Sbcvv7vznkpjli03bO', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1953, 'output_tokens': 11, 'total_tokens': 1964, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  ToolMessage(content='Current TODO List:\\n1. ‚è≥ Research the Model Context Protocol (MCP) and provide an overview. (pending)', name='read_todos', id='f7913d73-d3e3-458f-a981-9986623ff3f1', tool_call_id='call_2YEjZ1Sbcvv7vznkpjli03bO'),\n",
       "  AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 44, 'prompt_tokens': 1999, 'total_tokens': 2043, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 1792}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_3683ee3deb', 'id': 'chatcmpl-CsWKLpjhU9LLT6GdJ5jWG39MViTdj', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--019b6ff6-ed37-7181-bb80-27a58dec1c79-0', tool_calls=[{'name': 'task', 'args': {'description': 'Research the Model Context Protocol (MCP) including its definition, applications, and significance in the field of AI or software engineering.', 'subagent_type': 'research-agent'}, 'id': 'call_OBmaqMZQwJkekkPVI8q2Zxiv', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1999, 'output_tokens': 44, 'total_tokens': 2043, 'input_token_details': {'audio': 0, 'cache_read': 1792}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  ToolMessage(content=\"### Model Context Protocol (MCP)\\n\\n**Definition**\\nThe Model Context Protocol (MCP) is an open-source standard designed to connect AI applications to external systems. It enables these applications‚Äîsuch as Claude or ChatGPT‚Äîto integrate seamlessly with various data sources (including local files and databases), tools (like search engines and calculators), and workflows (like specialized prompts). This standardization simplifies the integration of AI applications, much like how USB-C simplifies device connectivity.\\n\\n**Applications**\\nMCP has a diverse array of applications, particularly in enhancing the capabilities of AI systems. Some examples include:\\n\\n1. **Data Access**: By using MCP, AI applications can access crucial information from a variety of sources, leading to improved performance and more informed decision-making.\\n2. **Tool Connectivity**: MCP facilitates connections to external tools, enhancing the functionality and versatility of AI applications. This includes integrating with search engines for enhanced information retrieval.\\n3. **Workflow Coordination**: With MCP, AI systems can automate workflows by connecting to different applications and services, thereby improving efficiency in task execution.\\n\\n**Significance in AI and Software Engineering**\\nThe MCP is significant for several reasons:\\n\\n- **Enhanced Integration**: It reduces the complexity and time required for developers to build or integrate AI applications by providing a standardized connection approach.\\n- **Improved User Experience**: For end-users, MCP results in more capable AI applications that can directly access their data and perform tasks autonomously, thereby increasing user satisfaction.\\n- **Industry Adoption**: As highlighted in recent industry reports, such as Gartner's 2025 Software Engineering Survey, a substantial proportion of API gateway vendors and iPaaS vendors are expected to adopt MCP features by 2026, indicating its rising importance in the software development landscape.\\n\\nIn summary, the Model Context Protocol represents a pivotal development in AI and software engineering, enhancing interoperability and functionality through a standardized approach to connecting applications to diverse data and tools.\", name='task', id='49a6ac0e-6ac8-41d5-8851-63d9bc088627', tool_call_id='call_OBmaqMZQwJkekkPVI8q2Zxiv'),\n",
       "  AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 114, 'prompt_tokens': 2437, 'total_tokens': 2551, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 1920}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_3683ee3deb', 'id': 'chatcmpl-CsWLJxQ6skrtC06xjYqde16BGWf1I', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--019b6ff7-dacd-72a1-ac05-b33b34ce90af-0', tool_calls=[{'name': 'think_tool', 'args': {'reflection': 'I successfully researched the Model Context Protocol (MCP) and gathered comprehensive information regarding its definition, applications, and significance in AI and software engineering. I found that MCP is an open-source standard that enhances the integration of AI applications with external systems, allowing for better access to data, tool connectivity, and workflow coordination. Its importance is underscored by its potential widespread adoption in various industries, facilitating more capable and user-friendly AI applications. \\n\\nNext, I will mark this task as completed.'}, 'id': 'call_OiaoDArk0o13btO2MHhpLgDZ', 'type': 'tool_call'}], usage_metadata={'input_tokens': 2437, 'output_tokens': 114, 'total_tokens': 2551, 'input_token_details': {'audio': 0, 'cache_read': 1920}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  ToolMessage(content='Reflection recorded: I successfully researched the Model Context Protocol (MCP) and gathered comprehensive information regarding its definition, applications, and significance in AI and software engineering. I found that MCP is an open-source standard that enhances the integration of AI applications with external systems, allowing for better access to data, tool connectivity, and workflow coordination. Its importance is underscored by its potential widespread adoption in various industries, facilitating more capable and user-friendly AI applications. \\n\\nNext, I will mark this task as completed.', name='think_tool', id='e05ac47c-9589-4596-a062-62cc4cfd3b8b', tool_call_id='call_OiaoDArk0o13btO2MHhpLgDZ'),\n",
       "  AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 35, 'prompt_tokens': 2660, 'total_tokens': 2695, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 2432}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_3683ee3deb', 'id': 'chatcmpl-CsWLNr0x0gUQzdHPHstP24pukjh4m', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--019b6ff7-ea5c-7d60-851a-e18bfb53eccd-0', tool_calls=[{'name': 'write_todos', 'args': {'todos': [{'content': 'Research the Model Context Protocol (MCP) and provide an overview.', 'status': 'completed'}]}, 'id': 'call_O7ZAcyyd7cgaDUdBgcXRknKW', 'type': 'tool_call'}], usage_metadata={'input_tokens': 2660, 'output_tokens': 35, 'total_tokens': 2695, 'input_token_details': {'audio': 0, 'cache_read': 2432}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  ToolMessage(content=\"Updated todo list to [{'content': 'Research the Model Context Protocol (MCP) and provide an overview.', 'status': 'completed'}]\", name='write_todos', id='052d2cfd-4a5a-493a-9cdf-9c9676c6905e', tool_call_id='call_O7ZAcyyd7cgaDUdBgcXRknKW'),\n",
       "  AIMessage(content=\"I have completed the research on the Model Context Protocol (MCP). Here's an overview:\\n\\n### Model Context Protocol (MCP)\\n\\n**Definition**: \\nThe Model Context Protocol (MCP) is an open-source standard that connects AI applications with external systems, enabling integration with data sources, tools, and workflows. It simplifies how AI applications like Claude or ChatGPT interface with different resources, similar to how USB-C simplifies connections between devices.\\n\\n**Applications**: \\nMCP enhances AI applications in several ways:\\n1. **Data Access**: Facilitates improved performance by allowing AI to gather data from various sources.\\n2. **Tool Connectivity**: Connects AI applications to external tools, broadening their functional capabilities.\\n3. **Workflow Coordination**: Automates processes by linking AI systems to different services, increasing task efficiency.\\n\\n**Significance in AI and Software Engineering**: \\n- **Enhanced Integration**: MCP minimizes integration complexity and development time by offering a standardized connection method.\\n- **Improved User Experience**: Enables AI applications to access user data and perform tasks more autonomously, enhancing satisfaction.\\n- **Industry Adoption**: A growing trend suggests that many API gateway and iPaaS vendors will adopt MCP features by 2026, highlighting its increasing relevance.\\n\\nThis protocol represents a significant step forward in AI and software engineering, facilitating interoperability and improving the functionality of applications. If you have any further questions or need more information, feel free to ask!\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 295, 'prompt_tokens': 2733, 'total_tokens': 3028, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 2560}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_3683ee3deb', 'id': 'chatcmpl-CsWLOYtiDlDlYOhcDD4WR0rDiYTVf', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b6ff7-ef99-79f1-a137-6dc6a7b769e2-0', usage_metadata={'input_tokens': 2733, 'output_tokens': 295, 'total_tokens': 3028, 'input_token_details': {'audio': 0, 'cache_read': 2560}, 'output_token_details': {'audio': 0, 'reasoning': 0}})],\n",
       " 'todos': [{'content': 'Research the Model Context Protocol (MCP) and provide an overview.',\n",
       "   'status': 'completed'}],\n",
       " 'files': {'URL_error_3oGBLl38.md': '# Search Result: What is the Model Context Protocol (MCP)? - Model Context Protocol\\n\\n**URL:** https://modelcontextprotocol.io/\\n**Query:** Model Context Protocol MCP definition applications significance AI software engineering\\n**Date:** Tue Dec 30, 2025\\n\\n## Summary\\n##### About MCP. ##### Develop with MCP. * Connect to local MCP servers. MCP (Model Context Protocol) is an open-source standard for connecting AI applications to external systems. Using MCP, AI applications like Claude or ChatGPT can connect to data sources (e.g. local files, databases), tools (e.g. search engines, calculators) and workflows (e.g. specialized prompts)‚Äîenabling them to access key information and perform tasks. Just as USB-C provides a standardized way to connect electronic devices, MCP provides a standardized way to connect AI applications to external systems. * **Developers**: MCP reduces development time and complexity when building, or integrating with, an AI application or agent. * **AI applications or agents**: MCP provides access to an ecosystem of data sources, tools and apps which will enhance capabilities and improve the end-user experience. * **End-users**: MCP results in more capable AI applications or agents which can access your data and take actions on your behalf when necessary. Develop applications that connect to MCP servers.\\n\\n## Raw Content\\n[Model Context Protocol home page](/)\\n\\n[Documentation](/docs/getting-started/intro)[Specification](/specification/2025-11-25)[Community](/community/communication)\\n\\n##### Get started\\n\\n* [What is MCP?](/docs/getting-started/intro)\\n\\n##### About MCP\\n\\n* [Architecture](/docs/learn/architecture)\\n* [Servers](/docs/learn/server-concepts)\\n* [Clients](/docs/learn/client-concepts)\\n* [Versioning](/specification/versioning)\\n\\n##### Develop with MCP\\n\\n* [Connect to local MCP servers](/docs/develop/connect-local-servers)\\n* [Connect to remote MCP Servers](/docs/develop/connect-remote-servers)\\n* [Build an MCP server](/docs/develop/build-server)\\n* [Build an MCP client](/docs/develop/build-client)\\n* [SDKs](/docs/sdk)\\n\\n##### Developer tools\\n\\n* [MCP Inspector](/docs/tools/inspector)\\n\\n* [What can MCP enable?](#what-can-mcp-enable)\\n* [Why does MCP matter?](#why-does-mcp-matter)\\n* [Start Building](#start-building)\\n* [Learn more](#learn-more)\\n\\nGet started\\n\\n# What is the Model Context Protocol (MCP)?\\n\\nMCP (Model Context Protocol) is an open-source standard for connecting AI applications to external systems. Using MCP, AI applications like Claude or ChatGPT can connect to data sources (e.g. local files, databases), tools (e.g. search engines, calculators) and workflows (e.g. specialized prompts)‚Äîenabling them to access key information and perform tasks. Think of MCP like a USB-C port for AI applications. Just as USB-C provides a standardized way to connect electronic devices, MCP provides a standardized way to connect AI applications to external systems.\\n\\n## [\\u200b](#what-can-mcp-enable) What can MCP enable?\\n\\n* Agents can access your Google Calendar and Notion, acting as a more personalized AI assistant.\\n* Claude Code can generate an entire web app using a Figma design.\\n* Enterprise chatbots can connect to multiple databases across an organization, empowering users to analyze data using chat.\\n* AI models can create 3D designs on Blender and print them out using a 3D printer.\\n\\n## [\\u200b](#why-does-mcp-matter) Why does MCP matter?\\n\\nDepending on where you sit in the ecosystem, MCP can have a range of benefits.\\n\\n* **Developers**: MCP reduces development time and complexity when building, or integrating with, an AI application or agent.\\n* **AI applications or agents**: MCP provides access to an ecosystem of data sources, tools and apps which will enhance capabilities and improve the end-user experience.\\n* **End-users**: MCP results in more capable AI applications or agents which can access your data and take actions on your behalf when necessary.\\n\\n## [\\u200b](#start-building) Start Building\\n\\n[## Build servers\\n\\nCreate MCP servers to expose your data and tools](/docs/develop/build-server)[## Build clients\\n\\nDevelop applications that connect to MCP servers](/docs/develop/build-client)\\n\\n## [\\u200b](#learn-more) Learn more\\n\\n[## Understand concepts\\n\\nLearn the core concepts and architecture of MCP](/docs/learn/architecture)\\n\\nWas this page helpful?\\n\\n[Architecture](/docs/learn/architecture)\\n',\n",
       "  'URL_error_10peEwBp.md': \"# Search Result: How Model Context Protocol (MCP) Simplifies AI Agent Development?\\n\\n**URL:** https://onereach.ai/blog/how-mcp-simplifies-ai-agent-development/\\n**Query:** Model Context Protocol MCP applications significance AI software engineering 2025\\n**Date:** Tue Dec 30, 2025\\n\\n## Summary\\nAccording to Gartner's 2025 Software Engineering Survey, by 2026, 75% of API gateway vendors and 50% of iPaaS vendors will have MCP features.\\n\\n## Raw Content\\nNo raw content available\\n\",\n",
       "  'top_10_mcp_use_cases_Ohqff_0n.md': '# Search Result: Top 10 MCP Use Cases - Using Claude & Model Context Protocol\\n\\n**URL:** https://www.youtube.com/watch?v=lzbbPBLPtdY\\n**Query:** Model Context Protocol MCP examples use cases AI software engineering\\n**Date:** Tue Dec 30, 2025\\n\\n## Summary\\nThe video discusses the top 10 use cases of the Model Context Protocol (MCP) alongside Claude AI. It presents a combination of factual insights and practical applications. Key points include the effective integration of MCP across various domains and the potential for enhanced task performance in AI applications.\\n\\n## Raw Content\\nTop 10 MCP Use Cases - Using Claude & Model Context Protocol - YouTube[About](https://www.youtube.com/about/)[Press](https://www.youtube.com/about/press/)[Copyright](https://www.youtube.com/about/copyright/)[Contact us](/t/contact_us/)[Creator](https://www.youtube.com/creators/)[Advertise](https://www.youtube.com/ads/)[Developers](https://developers.google.com/youtube)[Terms](/t/terms)[Privacy](/t/privacy)[Policy & Safety](https://www.youtube.com/about/policies/)[How YouTube works](https://www.youtube.com/howyoutubeworks?utm_campaign=ytgen&utm_source=ythp&utm_medium=LeftNav&utm_content=txt&u=https%3A%2F%2Fwww.youtube.com%2Fhowyoutubeworks%3Futm_source%3Dythp%26utm_medium%3DLeftNav%26utm_campaign%3Dytgen)[Test new features](/new)\\n\\n¬© 2025 Google LLC\\n',\n",
       "  'URL_error_8Sa9sM5G.md': '# Search Result: What is the Model Context Protocol (MCP)? - Model Context ...\\n\\n**URL:** https://modelcontextprotocol.io/\\n**Query:** Model Context Protocol MCP detailed examples AI software engineering applications\\n**Date:** Tue Dec 30, 2025\\n\\n## Summary\\n##### About MCP. ##### Develop with MCP. * Connect to local MCP servers. MCP (Model Context Protocol) is an open-source standard for connecting AI applications to external systems. Using MCP, AI applications like Claude or ChatGPT can connect to data sources (e.g. local files, databases), tools (e.g. search engines, calculators) and workflows (e.g. specialized prompts)‚Äîenabling them to access key information and perform tasks. Just as USB-C provides a standardized way to connect electronic devices, MCP provides a standardized way to connect AI applications to external systems. * **Developers**: MCP reduces development time and complexity when building, or integrating with, an AI application or agent. * **AI applications or agents**: MCP provides access to an ecosystem of data sources, tools and apps which will enhance capabilities and improve the end-user experience. * **End-users**: MCP results in more capable AI applications or agents which can access your data and take actions on your behalf when necessary. Develop applications that connect to MCP servers.\\n\\n## Raw Content\\n[Model Context Protocol home page](/)\\n\\n[Documentation](/docs/getting-started/intro)[Specification](/specification/2025-11-25)[Community](/community/communication)\\n\\n##### Get started\\n\\n* [What is MCP?](/docs/getting-started/intro)\\n\\n##### About MCP\\n\\n* [Architecture](/docs/learn/architecture)\\n* [Servers](/docs/learn/server-concepts)\\n* [Clients](/docs/learn/client-concepts)\\n* [Versioning](/specification/versioning)\\n\\n##### Develop with MCP\\n\\n* [Connect to local MCP servers](/docs/develop/connect-local-servers)\\n* [Connect to remote MCP Servers](/docs/develop/connect-remote-servers)\\n* [Build an MCP server](/docs/develop/build-server)\\n* [Build an MCP client](/docs/develop/build-client)\\n* [SDKs](/docs/sdk)\\n\\n##### Developer tools\\n\\n* [MCP Inspector](/docs/tools/inspector)\\n\\n* [What can MCP enable?](#what-can-mcp-enable)\\n* [Why does MCP matter?](#why-does-mcp-matter)\\n* [Start Building](#start-building)\\n* [Learn more](#learn-more)\\n\\nGet started\\n\\n# What is the Model Context Protocol (MCP)?\\n\\nMCP (Model Context Protocol) is an open-source standard for connecting AI applications to external systems. Using MCP, AI applications like Claude or ChatGPT can connect to data sources (e.g. local files, databases), tools (e.g. search engines, calculators) and workflows (e.g. specialized prompts)‚Äîenabling them to access key information and perform tasks. Think of MCP like a USB-C port for AI applications. Just as USB-C provides a standardized way to connect electronic devices, MCP provides a standardized way to connect AI applications to external systems.\\n\\n## [\\u200b](#what-can-mcp-enable) What can MCP enable?\\n\\n* Agents can access your Google Calendar and Notion, acting as a more personalized AI assistant.\\n* Claude Code can generate an entire web app using a Figma design.\\n* Enterprise chatbots can connect to multiple databases across an organization, empowering users to analyze data using chat.\\n* AI models can create 3D designs on Blender and print them out using a 3D printer.\\n\\n## [\\u200b](#why-does-mcp-matter) Why does MCP matter?\\n\\nDepending on where you sit in the ecosystem, MCP can have a range of benefits.\\n\\n* **Developers**: MCP reduces development time and complexity when building, or integrating with, an AI application or agent.\\n* **AI applications or agents**: MCP provides access to an ecosystem of data sources, tools and apps which will enhance capabilities and improve the end-user experience.\\n* **End-users**: MCP results in more capable AI applications or agents which can access your data and take actions on your behalf when necessary.\\n\\n## [\\u200b](#start-building) Start Building\\n\\n[## Build servers\\n\\nCreate MCP servers to expose your data and tools](/docs/develop/build-server)[## Build clients\\n\\nDevelop applications that connect to MCP servers](/docs/develop/build-client)\\n\\n## [\\u200b](#learn-more) Learn more\\n\\n[## Understand concepts\\n\\nLearn the core concepts and architecture of MCP](/docs/learn/architecture)\\n\\nWas this page helpful?\\n\\n[Architecture](/docs/learn/architecture)\\n'}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
